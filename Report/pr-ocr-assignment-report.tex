\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{hyperref}
\usepackage{soul}
\usepackage{float}
\usepackage{amsmath}
\usepackage{framed}
\usepackage[sc]{mathpazo}
\linespread{1.20}
\usepackage[T1]{fontenc}
\usepackage{microtype}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{courier}
\usepackage{enumitem}
\usepackage{lipsum}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{light-gray}{gray}{0.95}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true,language=Matlab}
\lstset{frame=single,commentstyle=\color{mygreen}}
\lstset{aboveskip=0.5cm,belowskip=0.3cm}
\lstset{backgroundcolor=\color{light-gray}}

\graphicspath{ {./images/} }

\hypersetup{pdfpagemode=UseNone}

\newcommand{\todo}[1] {\hl{TODO: #1}}

\setlength{\parindent}{0cm}

\begin{document}

\title{The Classification of Individual Digits \\ Using Pattern Recognition Techniques}
\author{Tom Runia \& Arnold Schutter}

\maketitle

Optical Character Recognition (OCR) is the conversion of scanned images containing written or printed text into machine-encoded text using pattern recognition. It is widely used in our modern world, for example to automatically read out passport documents or bank statements. In this paper we employ various pattern recognition techniques to classify individual digits in bank account numbers. The implementation is done using Matlab and the pattern recognition toolbox PRtools \cite{prtools-manual}. This article was written as part of the graduate course Pattern Recognition given at Delft University of Technology.

\section{Introduction}
The goal of this paper is to research the possibilies of using pattern recognition techniques to classify individual handwritten digits on bank statements. There are two scenarios that we are interested in. In the first scenario the OCR system is only trained once and then applied to the field. The second scenario allows the system to be trained for each batch of cheques. Both of these scenarios are worked out by training and testing on the standard dataset of handwritten digits which is available for free through the US National Institute of Standards \& Technologies (NIST). \\

The strucure of this article is as follows. We start off by discussing the first scenario and presenting our solution to the problem. Also we report our design choices and present some test results regarding the classification performance. Then we continue by discussing the second scenario in the same manner. Finally we review our work in the conclusion and give some recommendations for future work.

\section{Scenario 1: \textit{System is trained once}}

As already mentioned, this scenario only allows the recognition system to be trained once. After this initial training phase the system should be able to recognize individual digits with an error rate lower than $5\%$. This means that we should use a large amount of training data in order to allow accurate classification. Because of the presence of a lot of training data, there are many ways to train a classifier. We will try to find an optimum between the amount of features, the kind of features, the manipulation of them and the classifier. \st{The available time for the project forces us to make decisions for skipping methods, so sometimes choices will be made for rejecting or skipping classification methods based on the result of a single measurement.} 

\subsection{Classifying raw pixels}
The first way of classifying is to use the raw pixels of the image without filtering or adding extra features. Since the images contain $256 \times 256$ pixels, using all the pixels yields an amount of features bigger than the size of the training set. To avoid the \emph{curse of dimensionality} we lower the amount of features by scaling the images with the image-mapping tools in \texttt{PRTools}. The optimal size and the optimal way of interpolating the pixels is found empirically. For the classification are complex classifiers preferred above less complex classifiers, because of the presence of a lot of available features. However, to make it possible to compare different classifiers on different pixel-sizes, also less complex classifiers are used such as \textit{linear discriminant classifier} and \textit{nearest mean classifier}. The results are shown in Table~\ref{table:results-only-pixels}.

% Table of classifiers on raw pixels
\begin{table}[H]
  \centering
    \begin{tabular}{l|l|llllll}
    \hline
    Scaletype & Pixels & parzen & ldc   & qdc   & fisher & nmc   & knnc \\
		\hline
    \textbf{bicubic} & 8x8   & \textbf{0,039} & 0,109 & 0,054 & 0,136 & 0,189 & 0,046 \\
    \textbf{} & 9x9   & \textbf{0,036} & 0,67  & 0,191 & 0,129 & 0,193 & 0,049 \\
    \textbf{} & 10x10 & \textbf{0,021} & 0,885 & 0,488 & 0,12  & 0,15  & 0,023 \\
    \textbf{} & 11x11 & \textbf{0,03} & 0,899 & 0,65  & 0,141 & 0,187 & 0,032 \\
    \textbf{} & 12x12 & \textbf{0,044} & 0,897 & 0,675 & 0,159 & 0,194 & \textbf{0,044} \\
    \textbf{} & 13x13 & \textbf{0,041} & 0,9   & 0,69  & 0,146 & 0,198 & 0,042 \\
		\hline
    \textbf{nearest} & 8x8   & \textbf{0,109} & 0,16  & 0,352 & 0,177 & 0,213 & 0,13 \\
    \textbf{} & 9x9   & \textbf{0,114} & 0,164 & 0,325 & 0,186 & 0,221 & 0,131 \\
    \textbf{} & 10x10 & \textbf{0,108} & 0,833 & 0,532 & 0,165 & 0,208 & 0,11 \\
    \textbf{} & 11x11 & \textbf{0,085} & 0,887 & 0,711 & 0,171 & 0,217 & 0,103 \\
    \textbf{} & 12x12 & \textbf{0,083} & 0,9   & 0,763 & 0,146 & 0,191 & 0,088 \\
    \textbf{} & 13x13 & \textbf{0,096} & 0,898 & 0,784 & 0,169 & 0,222 & 0,107 \\
		\hline
    \textbf{bilinear} & 8x8   & \textbf{0,029} & 0,111 & 0,049 & 0,14  & 0,188 & 0,032 \\
    \textbf{} & 9x9   & \textbf{0,047} & 0,798 & 0,284 & 0,142 & 0,203 & 0,049 \\
    \textbf{} & 10x10 & \textbf{0,032} & 0,895 & 0,579 & 0,14  & 0,199 & 0,038 \\
    \textbf{} & 11x11 & \textbf{0,039} & 0,898 & 0,689 & 0,151 & 0,192 & 0,042 \\
    \textbf{} & 12x12 & 0,041 & 0,899 & 0,719 & 0,147 & 0,198 & \textbf{0,04} \\
    \textbf{} & 13x13 & \textbf{0,04} & 0,9   & 0,712 & 0,134 & 0,16  & \textbf{0,04} \\
		\hline
    \textbf{} & Best  & \textbf{0,021} & 0,109 & 0,049 & 0,12  & 0,15  & 0,023 \\
    \hline
    \end{tabular}%
		\caption{Error rates of various classifiers using pixels with different sizes and scaling types 
		\label{table:results-only-pixels}}
\end{table}

The results in the table show that the parzen and k-nearest neighbor classifiers perform best, the latter performs above expectations. The good performance of the k-nearest neighbor classifier raises the idea that the pixels per class cluster well. The quadratic bayes normal classifier (qdc) performs a bit worse, from this we conclude that the measurements of each class are not well normally distributed. As expected, the rest of the classifiers, all non-complex, perform worse. \\

Another classifier that we use is the \textit{support vector classifier (svc)}, which is a more complex classifier. This classifier is mentioned apart, because of the amount of variable options. The classifier is able to use different kernels which are listed below and can vary the weights the features can be weighted with. 

\begin{itemize}[noitemsep]
    \item Polynomial kernel (P)
    \item Exponential kernel (E)
    \item Radial kernel (R)
    \item Sigmoid kernel (S)
    \item Distance kernel (D)
    \item Minkowski kernel (M)
    \item City-Block kernel (C)
\end{itemize}

Only for the kernels \textit{polynomial} and \textit{radial} it was really useful to change the weight. Therefore the error-rates for the classifications with optimal weights for these kernels are shown in the tabel. Some of the kernels are ignored, since the results were not so well. The error-rates for different images sizes and interpolation methods are shown in Table~\ref{table: error rate SVC} . 

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[H]
  \centering
    \begin{tabular}{l|l|lllllll}
    \hline
    Scaletype & Pixelsize & P     & P (w=2) & S     & D     & R     & R (w=2,5) & E \\ 
    \hline
    \textbf{bicubic} & 8x8   & 0,045 & 0,035 & 0,668 & 0,172 & 0,05  & \textbf{0,029} & 0,033 \\
    \textbf{} & 9x9   & 0,045 & 0,031 & 0,666 & 0,188 & 0,111 & \textbf{0,025} & 0,034 \\
    \textbf{} & 10x10 & 0,048 & 0,028 & 0,73  & 0,187 & 0,222 & \textbf{0,024} & 0,031 \\
    \textbf{} & 11x11 & 0,046 & \textbf{0,024} & 0,769 & 0,177 & 0,319 & 0,026 & 0,05 \\
    \textbf{} & 12x12 & 0,055 & 0,028 & 0,792 & 0,177 & 0,527 & \textbf{0,027} & 0,047 \\
    \textbf{} & 13x13 & 0,038 & \textbf{0,026} & 0,834 & 0,184 & 0,662 & \textbf{0,026} & 0,055 \\ \hline
    \textbf{nearest} & 8x8   & 0,107 & 0,067 & 0,719 & 0,212 & 0,389 & \textbf{0,057} & 0,086 \\
    \textbf{} & 9x9   & 0,111 & 0,074 & 0,742 & 0,247 & 0,701 & \textbf{0,056} & 0,096 \\
    \textbf{} & 10x10 & 0,098 & 0,065 & 0,708 & 0,21  & 0,765 & \textbf{0,058} & 0,087 \\
    \textbf{} & 11x11 & 0,117 & \textbf{0,051} & 0,772 & 0,219 & 0,86  & 0,058 & 0,107 \\
    \textbf{} & 12x12 & 0,086 & \textbf{0,044} & 0,799 & 0,203 & 0,831 & 0,065 & 0,101 \\
    \textbf{} & 13x13 & 0,088 & \textbf{0,045} & 0,798 & 0,215 & 0,839 & 0,082 & 0,11 \\ \hline
    \textbf{bilinear} & 8x8   & 0,035 & 0,033 & 0,586 & 0,169 & 0,029 & \textbf{0,02} & 0,024 \\
    \textbf{} & 9x9   & 0,052 & 0,033 & 0,662 & 0,182 & 0,06  & \textbf{0,027} & 0,036 \\
    \textbf{} & 10x10 & 0,032 & 0,02  & 0,699 & 0,18  & 0,122 & \textbf{0,017} & 0,024 \\
    \textbf{} & 11x11 & 0,044 & 0,029 & 0,742 & 0,198 & 0,241 & \textbf{0,028} & 0,042 \\
    \textbf{} & 12x12 & 0,058 & 0,039 & 0,837 & 0,188 & 0,315 & \textbf{0,029} & 0,05 \\
    \textbf{} & 13x13 & 0,049 & 0,029 & 0,835 & 0,198 & 0,487 & \textbf{0,028} & 0,052 \\ \hline
    \textbf{} & Best  & 0,032 & 0,02  & 0,586 & 0,169 & 0,029 & \textbf{0,017} & 0,024 \\
    \hline
    \end{tabular}
  \caption{Error rates after SVC classification with different kernels and weights} \label{table: error rate SVC}
\end{table}%

The results show that SVC performs best for the weighted polynomial, the weighted radial and the exponential kernels. Therefore the SVC results will only be shown for these settings from now on. The tables above show both that the interpolation type nearest is not giving good results, therefore this type of interpolation will be skipped from now on. \\

After optimizing the scaling of the images and finding the best classifier, which are the parzen classifier and the support vector classifier in this case, the next step will be to lower the error-rate more. Therefore extra features will be produced with the imaging features function of \emph{PRTools}. 

\subsection{Classifying standard extra features}

There are several ways of extracting features e.g. the\textit{eccentricity}, the \textit{centroid} and the \textit{major axis length} from the images. These extra features can be generated by using the Matlab function \textit{im$\_$features}, which generates 23 extra features. The same classifiers are tested on these computed extra features. Since there are less features than pixels, it is assumed that the most complex classifiers will perform worse and the less complex classifiers will relatively perform better. The results after performing the tests were really bad, with error rates between 10 until 80$\%$, therefore the results will not be shown. The confusion matrix of one of the best test results is shown in the table below, this shows for every object per class how it is classified. 

\begin{table}[H]
  \centering
    \begin{tabular}{l|llllllllll|l}
    \hline
    True  & \multicolumn{10}{c}{Estimated labels}                                         &  \\
    \hline
    Labels & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{5} & \multicolumn{1}{l}{6} & \multicolumn{1}{l}{7} & \multicolumn{1}{l}{8} & \multicolumn{1}{l}{9} & Totals \\ \hline
    0     & \multicolumn{1}{l}{85} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{1} & 100 \\
    1     & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{99} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & 100 \\
    2     & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{55} & \multicolumn{1}{l}{14} & \multicolumn{1}{l}{8} & \multicolumn{1}{l}{8} & \multicolumn{1}{l}{7} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{1} & 100 \\
    3     & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{7} & \multicolumn{1}{l}{82} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{2} & 100 \\
    4     & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{65} & \multicolumn{1}{l}{11} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{5} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{5} & 100 \\
    5     & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{8} & \multicolumn{1}{l}{15} & \multicolumn{1}{l}{8} & \multicolumn{1}{l}{62} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{2} & 100 \\
    6     & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{86} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{0} & 100 \\
    7     & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{4} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{88} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{3} & 100 \\
    8     & \multicolumn{1}{l}{11} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{69} & \multicolumn{1}{l}{7} & 100 \\
    9     & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{2} & \multicolumn{1}{l}{1} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{0} & \multicolumn{1}{l}{7} & \multicolumn{1}{l}{3} & \multicolumn{1}{l}{80} & 100 \\ \hline
    Totals & \multicolumn{1}{l}{111} & \multicolumn{1}{l}{107} & \multicolumn{1}{l}{83} & \multicolumn{1}{l}{122} & \multicolumn{1}{l}{96} & \multicolumn{1}{l}{91} & \multicolumn{1}{l}{96} & \multicolumn{1}{l}{108} & \multicolumn{1}{l}{85} & \multicolumn{1}{l}{101} & 1000 \\
    \hline
    \end{tabular}%
  \label{table: confusion matrix on features}   \caption{Confusion matrix for direct classification on features}
\end{table}%

Note that in the confusion matrix the number one is classified quite well, the 5 is often confused for 3, the 8 for 0 and the numbers 2, 4 and 5 are badly classified in general. The features are not representing the numbers well enough and this causes problems. We tried to compute the features in different ways, classifying and mapping them in different ways (including PCA), but it doesn't give the expected results. 

\subsection{Classifying PCA mapped data}
\label{sec: Classifying PCA mapped data}
In the previous sections, a lot of features used for the classification may not contribute significantly, which is to be expected especially when using the pixels as features. It could be useful to map the feature space into a smaller but less correlated feature space. This is done by principal component analysis (PCA), which maps the feature space using orthogonal transformation. \\

The PCA can be performed after doing different types of scaling. The first type of scaling which is used is \textit{c-mean}: the mean is shifted to the origin. Since the scales of features vary a lot, we tried to normalize the variation of the features, therefore the \textit{c-variation} is used: the mean is shifted to the origin and the average class variances are normalized. The third used way of scaling is \textit{domain}, which sets the domain of all the features to [0,1]. The PCA is also performed on a non-scaled dataset. The used classifiers are equal to the classifiers above to be able to compare the differences. All the results are included in Appendix A, a summary is shown in the table below.

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[H]
  \centering
    \begin{tabular}{l|llllll|l}
    \hline
    \textbf{bicubic} & 8x8   & 9x9   & 10x10 & 11x11 & 12x12 & 13x13 & Min \\
    \hline \hline
    PCA c-var & 0,034 & 0,029 & 0,036 & 0,035 & 0,034 & 0,039 & 0,029 \\
    PCA c-mean & 0,027 & 0,024 & 0,019 & 0,024 & 0,021 & 0,029 & 0,019 \\
    PCA domain & 0,025 & 0,026 & 0,023 & \textbf{0,017} & 0,023 & 0,028 & 0,017 \\
    PCA unscaled & 0,023 & 0,024 & 0,023 & 0,021 & 0,034 & 0,033 & 0,021 \\ 
    Pixels & 0,028 & 0,027 & 0,026 & 0,022 & 0,027 & 0,031 & 0,022 \\ \hline
		Minimum   & 0,023 & 0,024 & 0,019 & 0,017 & 0,021 & 0,028 & 0,017 \\
		\hline
		\hline
    \textbf{bilinear} & 8x8   & 9x9   & 10x10 & 11x11 & 12x12 & 13x13 & Min \\ \hline
    PCA c-var & 0,032 & 0,033 & 0,037 & 0,041 & 0,038 & 0,033 & 0,032 \\
    PCA c-mean & 0,022 & 0,025 & 0,026 & 0,026 & 0,02  & 0,023 & 0,02 \\
    PCA domain & 0,025 & 0,025 & 0,029 & 0,024 & 0,019 & 0,025 & 0,019 \\
    PCA unscaled & 0,024 & \textbf{0,017} & 0,019 & 0,025 & 0,022 & 0,028 & 0,017 \\
    Pixels & 0,023 & 0,028 & 0,021 & 0,035 & 0,029 & 0,025 & 0,021 \\ \hline
		Minimum & 0,022 & 0,017 & 0,019 & 0,024 & 0,019 & 0,023 & 0,017 \\ 
    \hline
    \end{tabular}%
    \caption{Minimum error rates summary of all used classifiers after PCA per size, scalingmethod and mapping type} \label{table: error rate summary PCA}%
\end{table}%

The summary table shows that domain scaling and no scaling perform best, but that c-mean is also performing well. It is surprising that classifying on the raw images gives an only little worse error rate. Besides the summary to show which scaling type performs best at which pixel size, also the performance of the classifiers will be shown per scaling type, neglecting the size of the images. 

\begin{table}[H]
  \centering
    \begin{tabular}{l|llllllllll|l}
    \hline
     & & & & & & & &  & \textbf{SVC P} & \textbf{SVC R} &  \\
    \hline
          & \multicolumn{1}{l}{\textbf{parzen}} & \multicolumn{1}{l}{\textbf{ldc}} & \multicolumn{1}{l}{\textbf{qdc}} & \multicolumn{1}{l}{\textbf{fisher}} & \multicolumn{1}{l}{\textbf{nmc}} & \multicolumn{1}{l}{\textbf{knn}} & \multicolumn{1}{l}{\textbf{SVC P}} & \multicolumn{1}{l}{\textbf{SVC E}} & \textbf{(w=2)} & \textbf{(w=2.5)} & \multicolumn{1}{l}{\textbf{min}} \\ \hline
    PCA c-var & \multicolumn{1}{l}{0,041} & \multicolumn{1}{l}{0,093} & \multicolumn{1}{l}{0,044} & \multicolumn{1}{l}{0,121} & \multicolumn{1}{l}{0,164} & \multicolumn{1}{l}{0,035} & \multicolumn{1}{l}{0,052} & \multicolumn{1}{l}{0,237} & 0,029 & 0,324 & \multicolumn{1}{l}{0,029} \\
    PCA c-mean & \multicolumn{1}{l}{0,024} & \multicolumn{1}{l}{0,104} & \multicolumn{1}{l}{0,029} & \multicolumn{1}{l}{0,125} & \multicolumn{1}{l}{0,161} & \multicolumn{1}{l}{0,026} & \multicolumn{1}{l}{0,043} & \multicolumn{1}{l}{0,031} & 0,02  & 0,019 & \multicolumn{1}{l}{0,019} \\
    PCA domain & \multicolumn{1}{l}{0,028} & \multicolumn{1}{l}{0,098} & \multicolumn{1}{l}{0,03} & \multicolumn{1}{l}{0,135} & \multicolumn{1}{l}{0,173} & \multicolumn{1}{l}{0,032} & \multicolumn{1}{l}{0,035} & \multicolumn{1}{l}{0,031} & \textbf{0,017} & 0,021 & \multicolumn{1}{l}{0,017} \\
    PCA unscaled & \multicolumn{1}{l}{0,03} & \multicolumn{1}{l}{0,103} & \multicolumn{1}{l}{0,035} & \multicolumn{1}{l}{0,13} & \multicolumn{1}{l}{0,17} & \multicolumn{1}{l}{0,032} & \multicolumn{1}{l}{0,042} & \multicolumn{1}{l}{0,038} & 0,022 & 0,026 & \multicolumn{1}{l}{0,022} \\
    Pixels & \multicolumn{1}{l}{0,027} & \multicolumn{1}{l}{0,68} & \multicolumn{1}{l}{0,151} & \multicolumn{1}{l}{0,121} & \multicolumn{1}{l}{0,167} & \multicolumn{1}{l}{0,025} & \multicolumn{1}{l}{0,04} & \multicolumn{1}{l}{0,037} & 0,023 & 0,021 & \multicolumn{1}{l}{0,021} \\ \hline
    Min   & \multicolumn{1}{l}{0,024} & \multicolumn{1}{l}{0,093} & \multicolumn{1}{l}{0,029} & \multicolumn{1}{l}{0,121} & \multicolumn{1}{l}{0,161} & \multicolumn{1}{l}{0,025} & \multicolumn{1}{l}{0,035} & \multicolumn{1}{l}{0,031} & 0,017 & 0,019 & \multicolumn{1}{l}{0,017} \\
    \hline
    \end{tabular}%

  \caption{Minimum error rates of all sizes per classifier, scalingmethod and mapping type} \label{table: error rate summary PCA2}   
\end{table}% 

From the table we conclude that the support vector classifier for the \textit{polynomial} and \textit{radial kernel} perform best while using the scaling \textit{c-mean} and \textit{domain}. 



\subsection{Classifying extra features with DIP image}














\section{Scenario 2: \textit{System is trained for each batch}}

The second scenario allows the classifier to be trained for every batch of cheques to be processed. As a concequence the dataset available for training is much smaller, in this scenario we train the classifier using at most $10$ objects per class. The target for this assignment is $25\%$ test error.

\subsection{Representation}
Again the development of our algorithm begins with choosing the best representation for our data set. Here we need to take into account that the number of objects that are available for training is small compared to the first scenario. Therefore the information in the raw pixel features as were used in the first part is probably not sufficient. We are left with two options, calculate various \emph{image features} or choose the path of \emph{dissimilarities}. \todo{Why did we choose for features?} \\

The standard methods of Matlab supplemented with the \texttt{PRtools} is limited in image analysis. By choosing the image feature representation we needed a flexible and powerful image processing toolkit for Matlab. We have chosen to incorporate \texttt{DIPimage} for our project since we already had experience with it and integrates nicely with \texttt{PRtools}.

\subsection{Feature Selection}

After converting our images to \texttt{DIPimage} objects we can exploit the \texttt{measurement} method that allows easy computation of a large amount of image statistics and more. We have selected a large amount of these statistics to use as features. In the selection process we have intuitively picked the features which we thought are differentiating the digits. Table~\ref{table:image-features} lists the features that were initially used as features. \todo{Write down the number of features per entry in the table since some of them contain multiple values (x,y etc)}

\begin{table}[H]
	\centering
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Feature} & \textbf{Description} \\
    \hline
    \emph{Object Count}     & Number of objects, sometimes there are two smaller objects \\
    \emph{Total Size}       & Total number of object pixels           \\
    \emph{Radius}       	& Statistics on the radius using chain-code method           \\
    \emph{Center}  		& Coordinates of the geometric mean \\
    \emph{Gravity} 		& Coordinates of the center-of-mass \\
    \emph{Inertia} 		& Moments of intertia \\
    \emph{Mu} 				& Elements of the inertia tensor \\
    \emph{ConvexArea} 		& Area of the convex hull \\
    \emph{CartesianBox} 	& Cartesian box size around the object \\
    \emph{CCBendingEnergy} & Bending energy of the object perimeter \\
    \emph{Convexity} 		& Area fraction of convex hull covered by the object \\
    \emph{Feret} 			& Minimum and maximum object diameters \\
    \emph{Mean} 			& Mean object intensity \\
    \emph{Circularity} 	& Circularity of the object \\
    \emph{Perimeter} 		& Length of the object perimeter (chain-code) \\
    \emph{Sum of Pixels} 	& Sum of object intensity (mass) \\
    \hline
    \end{tabular}
    \caption{Image features computed by DIPimage's \texttt{measurement} function \label{table:image-features}}
\end{table}

\subsection{Initial Results and Optimal Classifier}

Having obtained the feature matrix and converted this to data set we did some initial testing on the features. To this end we loaded the entire NIST dataset, from this we generated two datasets, one for training and one for testing. The training dataset contains $10$ objects per class, for testing we selected $50$ objects per class. \\

We started training with various classifiers; \emph{nearest-mean}, \emph{fisher}, \emph{parzen}, \emph{k-nearest neighbor} and \emph{support vector machines}. The training and test phase with the class sizes as stated above were repeated five times in order to get representative results, our foundings are listed in Table~\ref{table:results-only-features}. For each result the best performance (lowest error) is indicated in bold. 

\begin{table}[H]
	\centering
    \begin{tabular}{|l|lllll|}
    \hline
	& \textbf{1NN} & \textbf{Parzen} & \textbf{Fisher} & \textbf{NMC} & \textbf{SVC} \\
	\hline
	1 & 0.3280 &  0.3100 &   0.2940 &   0.3340 &   \textbf{0.2520} \\
	2 & 0.2860 &  0.2880 &   0.2540 &   0.3420 &   \textbf{0.2520} \\		
	3 & 0.3840 &  0.3100 &   \textbf{0.2560} &   0.3620 &   0.3140 \\	
	4 & 0.3660 &  0.3420 &   0.2860 &   0.3360 &   \textbf{0.2780} \\
	5 & 0.3340 &  0.2980 &   0.3000 &   0.3960 &   \textbf{0.2540} \\
	\hline
    \end{tabular}
    \caption{Error rates of various classifiers using $29$ image features \label{table:results-only-features}}
\end{table}

From these measurements we directly notice that using support vector machines with polynomial kernel as classifier yields the best result with an average error rate of $27\%$. Although this is a good initial result, we want to decrease the error rate.

\subsection{Improving the Error Rate}

First we want to see the effect of using different kernels with SVC. This is done by applying the same settings as above and training SVC with the seven different kernels.

After performing tests with these kernels we quickly concluded to stick to the \emph{polynomial kernel} since it extremely outperformed the others. The results are shown in Table~\ref{table:results-svc-kernels} with the best result indicated in bold font.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|lllllll|}
    \hline
    & \textbf{P} & \textbf{E} & \textbf{R} & \textbf{S} & \textbf{D} & \textbf{M} & \textbf{C} \\
    \hline
    1 & \textbf{0.2520} &   0.6080 &   0.7160 &   0.4660 &   0.9980 & 0.9980 &   0.9980 \\
    2 & \textbf{0.2840} &   0.5080 &   0.7340 &   0.4980 &   1.0000 & 0.9980 &   0.9980 \\
    3 & \textbf{0.2780} &   0.7600 &   0.7560 &   0.5160 &   0.9940 & 0.9940 &   0.9940 \\
    4 & \textbf{0.2640} &   0.6360 &   0.8180 &   0.5060 &   1.0000 & 0.9980 &   0.9980 \\
    5 & \textbf{0.2520} &   0.8020 &   0.8420 &   0.5460 &   0.9960 & 1.0000 &   1.0000 \\
    \hline
    \end{tabular}
    \caption{Error rates using SVC with different kernels \label{table:results-svc-kernels}}
\end{table}

We also wanted to try adding more features to the dataset returned by the \texttt{my\_rep} function. In order to do this, two options were available to us, first we could compute more (advanced) image features, and second we could down-scale the images and add the pixel values as features. Since we already maximally exploited DIPimage's \texttt{measure} function to compute image features we chose to test the second method first. \\

The \texttt{my\_rep} function was modified so that it also down-scales the image to square size of $d \times d$ pixels. Before doing this we applied \emph{gaussian smoothing} to the digits and then applied resampling using \emph{Lanczos method} \cite{lanczos-filtering} as implemented by DIPimage. Our approach is to start by down-scaling the image by a large factor (small $d$) so that little pixels are added as features. We perform classification of our SVC using polynomial kernel and analyze the error rate. Then we continue increasing $d$ and see what effect this has on the error rate.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|lllllllll|}
    \hline
    $d$ & $4$ & $6$ & $8$ & $10$ & $12$ & $13$ & $14$ & $15$ & $16$ \\
    \hline
    1 & 0.2860 & 0.1960 & 0.2120 & 0.1620 & 0.1700 & 0.1540 & 0.1680 & 0.1700 & 0.1540 \\
    2 & 0.3100 & 0.2540 & 0.2380 & 0.2180 & 0.1800 & 0.1760 & 0.1660 & 0.1600 & 0.2100 \\
    3 & 0.2600 & 0.2540 & 0.2480 & 0.1680 & 0.1640 & 0.1620 & 0.1600 & 0.1980 & 0.1940 \\
    4 & 0.2400 & 0.2120 & 0.2180 & 0.1700 & 0.1880 & 0.1920 & 0.1740 & 0.1740 & 0.1920 \\
    \hline
      & 0.2740 & 0.2290 & 0.2290 & 0.1795 & 0.1755 & 0.1710 & \textbf{0.1670} & 0.1755 & 0.1875 \\
    \hline
    \end{tabular}
    \caption{Error rates using SVC and additional $d \times d$ pixel features \label{tab:svc-adding-pixel-features}}
\end{table}

From the results, displayed in Table~\ref{tab:svc-adding-pixel-features}, we notice a declining error rate if we add more pixels as features. However the average error rate increases if we continue to increase the image size beyond $14 \times 14$ pixels. One hypothesis about this increasing error rate beyond this size is that it is account for by the \emph{curse of dimensionality}. In conclusion we can say that the best results with an average error rate of $\mathbf{16.7 \%}$ were achieved using $29$ image features and $196$ additional pixel features. 

\subsection{Misclassification of Individual Digits}

To better understand our results we analyzed the misclassification rates per individual digit. This allows us to determine which of the digits are hard to correctly classify and give insight in how to improve our algorithm. Obtaining these numbers was straight forward, we performed classification $8$ times and averages the misclassification rates. The results are displayed in Figure~\ref{fig:digit-misclassification}. \\

The chart displays the error rates per digit and directly shows us that digit $8$ is most often misclassified whereas the digit $0$ has the lowest error rate. \todo{explain why these digits are the highest and lowest, probably the best is to give some examples in picture form.}

\begin{figure}[H]
    \center
    \includegraphics[width=.7\textwidth]{misclassification-digits}
    \caption{Misclassification rates per digit (average over $8$ batches) \label{fig:digit-misclassification}}
\end{figure}

\section{Recommendations}

In this section we discuss possible improvements for the classifiers we have presented in this article. \todo{Discuss possible improvements for scenario 1} \\

Also we discuss the possibilities for improving the algorithm for the second scenario. For this scenario there are two possible ways to improve the classifier. First the accuracy of the classifier can be increased, whereas the second enhancement focusses on computing time. For improving the error rates adding more pixel features is not the way to go as the results in Table~\ref{tab:svc-adding-pixel-features} shows. We recommend using less pixel values but select them more carefully by calculating which pixels contain most information. This can be done by incorporating the \emph{Shannon entropy} of the pixels and selecting the ones that are most valuable. \todo{this is not finished}


\section{Appendix A: Result matrices}

The matrix of the error-rates after applying different classifiers on PCA-mapped images and on raw pixels is shown below. The resizing is only done for scale $8 \times 8$ until $13 \times 13$ for bilinear and cubical interpolation of pixels, because the best results are gotten for these settings. The lowest error-rate is written in bold.

\begin{table}[H]
  \centering
    \begin{tabular}{l|l|llllllllll|l}
    \hline
    \textbf{size} & \textbf{PCA-mapping} & \textbf{parzen} & \textbf{ldc} & \textbf{qdc} & \textbf{fisher} & \textbf{nmc} & \textbf{knnc} & \textbf{svc p} & \textbf{svc e} & \textbf{svc p2} & \textbf{svc r2.5} & \textbf{min} \\
    \hline \hline
    8x8   & PCA c-var & 0,041 & 0,115 & 0,052 & 0,152 & 0,21  & 0,047 & 0,052 & 0,249 & 0,034 & 0,324 & 0,034 \\
          & PCA c-mean & 0,032 & 0,106 & 0,034 & 0,125 & 0,162 & 0,033 & 0,047 & 0,035 & 0,03  & 0,027 & 0,027 \\
          & PCA domain & 0,043 & 0,106 & 0,039 & 0,135 & 0,195 & 0,049 & 0,049 & 0,035 & 0,025 & 0,029 & 0,025 \\
          & PCA pixels & 0,037 & 0,107 & 0,045 & 0,139 & 0,19  & 0,04  & 0,044 & 0,038 & 0,028 & 0,028 & 0,028 \\
          & pixels & 0,036 & 0,68  & 0,151 & 0,141 & 0,181 & 0,032 & 0,043 & 0,037 & 0,023 & 0,026 & 0,023 \\ \hline
    9x9   & PCA c-var & 0,043 & 0,097 & 0,044 & 0,121 & 0,195 & 0,035 & 0,053 & 0,237 & 0,029 & 0,358 & 0,029 \\
          & PCA c-mean & 0,032 & 0,125 & 0,042 & 0,163 & 0,209 & 0,027 & 0,053 & 0,039 & 0,024 & 0,028 & 0,024 \\
          & PCA domain & 0,045 & 0,13  & 0,041 & 0,157 & 0,193 & 0,045 & 0,052 & 0,045 & 0,026 & 0,031 & 0,026 \\
          & PCA pixels & 0,032 & 0,12  & 0,042 & 0,153 & 0,202 & 0,034 & 0,051 & 0,04  & 0,031 & 0,027 & 0,027 \\
          & pixels & 0,031 & 0,887 & 0,491 & 0,121 & 0,167 & 0,032 & 0,042 & 0,039 & 0,032 & 0,024 & 0,024 \\ \hline
    10x10 & PCA c-var & 0,048 & 0,11  & 0,065 & 0,142 & 0,203 & 0,048 & 0,066 & 0,26  & 0,036 & 0,453 & 0,036 \\
          & PCA c-mean & 0,024 & 0,104 & 0,029 & 0,127 & 0,187 & 0,026 & 0,043 & 0,031 & 0,02  & 0,019 & 0,019 \\
          & PCA domain & 0,034 & 0,098 & 0,03  & 0,135 & 0,173 & 0,036 & 0,035 & 0,031 & 0,023 & 0,023 & 0,023 \\
          & PCA pixels & 0,034 & 0,103 & 0,041 & 0,13  & 0,17  & 0,032 & 0,046 & 0,043 & 0,026 & 0,03  & 0,026 \\
          & pixels & 0,032 & 0,9   & 0,654 & 0,122 & 0,188 & 0,036 & 0,04  & 0,04  & 0,025 & 0,023 & 0,023 \\ \hline
    11x11 & PCA c-var & 0,043 & 0,097 & 0,054 & 0,129 & 0,164 & 0,039 & 0,063 & 0,356 & 0,035 & 0,508 & 0,035 \\
          & PCA c-mean & 0,033 & 0,109 & 0,034 & 0,136 & 0,161 & 0,035 & 0,048 & 0,046 & 0,031 & 0,024 & 0,024 \\
          & PCA domain & 0,028 & 0,119 & 0,035 & 0,151 & 0,183 & 0,035 & 0,047 & 0,031 & \textbf{0,017} & 0,021 & \textbf{0,017} \\
          & PCA pixels & 0,03  & 0,105 & 0,035 & 0,147 & 0,195 & 0,032 & 0,042 & 0,039 & 0,022 & 0,026 & 0,022 \\
          & pixels & 0,027 & 0,9   & 0,682 & 0,136 & 0,185 & 0,025 & 0,049 & 0,05  & 0,023 & 0,021 & 0,021 \\ \hline
    12x12 & PCA c-var & 0,056 & 0,111 & 0,061 & 0,141 & 0,191 & 0,055 & 0,071 & 0,395 & 0,034 & 0,578 & 0,034 \\
          & PCA c-mean & 0,038 & 0,106 & 0,036 & 0,126 & 0,186 & 0,043 & 0,049 & 0,041 & 0,021 & 0,024 & 0,021 \\
          & PCA domain & 0,033 & 0,101 & 0,039 & 0,14  & 0,196 & 0,032 & 0,049 & 0,033 & 0,026 & 0,023 & 0,023 \\
          & PCA pixels & 0,039 & 0,122 & 0,035 & 0,159 & 0,178 & 0,043 & 0,058 & 0,044 & 0,033 & 0,027 & 0,027 \\
          & pixels & 0,051 & 0,9   & 0,703 & 0,136 & 0,188 & 0,053 & 0,062 & 0,064 & 0,034 & 0,041 & 0,034 \\ \hline
    13x13 & PCA c-var & 0,052 & 0,093 & 0,054 & 0,131 & 0,191 & 0,051 & 0,065 & 0,424 & 0,039 & 0,625 & 0,039 \\
          & PCA c-mean & 0,042 & 0,128 & 0,037 & 0,151 & 0,195 & 0,038 & 0,064 & 0,046 & 0,03  & 0,029 & 0,029 \\
          & PCA domain & 0,045 & 0,108 & 0,03  & 0,145 & 0,181 & 0,052 & 0,054 & 0,051 & 0,028 & 0,028 & 0,028 \\
          & PCA pixels & 0,045 & 0,13  & 0,048 & 0,161 & 0,203 & 0,044 & 0,063 & 0,058 & 0,031 & 0,035 & 0,031 \\
          & pixels & 0,044 & 0,899 & 0,699 & 0,134 & 0,176 & 0,044 & 0,056 & 0,072 & 0,033 & 0,044 & 0,033 \\ \hline
          & min & 0,024 & 0,093 & 0,029 & 0,121 & 0,161 & 0,025 & 0,035 & 0,031 & \textbf{0,017} & 0,019 & 0,017 \\
    \hline
    \end{tabular}%
		\caption{Error rates on PCA mapped and raw pixels for bicubic interpolation between pixels}  \label{table: errorrates of PCA mappings bicubic}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[H]
  \centering
    \begin{tabular}{l|l|llllllllll|l}
    \hline
    \textbf{size} & \textbf{PCA-mapping} & \textbf{parzen} & \textbf{ldc} & \textbf{qdc} & \textbf{fisher} & \textbf{nmc} & \textbf{knnc} & \textbf{svc p} & \textbf{svc e} & \textbf{svc p2} & \textbf{svcr2.5} & \textbf{min} \\
    \hline \hline
    8x8   & PCA c-var & 0,032 & 0,109 & 0,05  & 0,143 & 0,197 & 0,033 & 0,065 & 0,265 & 0,034 & 0,328 & 0,032 \\
          & PCA c-mean & 0,037 & 0,119 & 0,034 & 0,14  & 0,204 & 0,039 & 0,044 & 0,037 & 0,022 & 0,023 & 0,022 \\
          & PCA domain & 0,03  & 0,115 & 0,046 & 0,142 & 0,184 & 0,043 & 0,049 & 0,031 & 0,025 & 0,025 & 0,025 \\
          & PCA pixels & 0,033 & 0,098 & 0,042 & 0,128 & 0,184 & 0,034 & 0,036 & 0,025 & 0,025 & 0,024 & 0,024 \\
          & pixels & 0,03  & 0,801 & 0,265 & 0,114 & 0,146 & 0,033 & 0,04  & 0,027 & 0,027 & 0,023 & 0,023 \\ \hline
    9x9   & PCA c-var & 0,04  & 0,109 & 0,04  & 0,139 & 0,189 & 0,039 & 0,065 & 0,28  & 0,033 & 0,37  & 0,033 \\
          & PCA c-mean & 0,039 & 0,109 & 0,044 & 0,125 & 0,19  & 0,043 & 0,049 & 0,037 & 0,033 & 0,025 & 0,025 \\
          & PCA domain & 0,032 & 0,089 & 0,034 & 0,11  & 0,161 & 0,031 & 0,039 & 0,034 & 0,025 & 0,026 & 0,025 \\
          & PCA pixels & 0,031 & 0,098 & 0,033 & 0,126 & 0,16  & 0,035 & 0,035 & 0,026 & 0,02  & \textbf{0,017} & \textbf{0,017} \\
          & pixels & 0,044 & 0,893 & 0,547 & 0,143 & 0,181 & 0,043 & 0,043 & 0,035 & 0,036 & 0,028 & 0,028 \\ \hline
    10x10 & PCA c-var & 0,053 & 0,121 & 0,057 & 0,147 & 0,214 & 0,052 & 0,074 & 0,28  & 0,037 & 0,47  & 0,037 \\
          & PCA c-mean & 0,031 & 0,122 & 0,051 & 0,159 & 0,182 & 0,033 & 0,055 & 0,035 & 0,028 & 0,026 & 0,026 \\
          & PCA domain & 0,029 & 0,123 & 0,035 & 0,154 & 0,183 & 0,029 & 0,048 & 0,042 & 0,029 & 0,031 & 0,029 \\
          & PCA pixels & 0,029 & 0,102 & 0,031 & 0,137 & 0,178 & 0,036 & 0,045 & 0,036 & 0,021 & 0,019 & 0,019 \\
          & pixels & 0,036 & 0,896 & 0,705 & 0,126 & 0,153 & 0,037 & 0,037 & 0,034 & 0,026 & 0,021 & 0,021 \\ \hline
    11x11 & PCA c-var & 0,05  & 0,112 & 0,046 & 0,142 & 0,197 & 0,048 & 0,061 & 0,362 & 0,041 & 0,529 & 0,041 \\
          & PCA c-mean & 0,042 & 0,112 & 0,044 & 0,145 & 0,187 & 0,045 & 0,05  & 0,04  & 0,026 & 0,026 & 0,026 \\
          & PCA domain & 0,029 & 0,098 & 0,04  & 0,122 & 0,166 & 0,035 & 0,042 & 0,035 & 0,026 & 0,024 & 0,024 \\
          & PCA pixels & 0,037 & 0,119 & 0,041 & 0,146 & 0,191 & 0,035 & 0,049 & 0,037 & 0,026 & 0,025 & 0,025 \\
          & pixels & 0,043 & 0,9   & 0,716 & 0,162 & 0,194 & 0,043 & 0,049 & 0,055 & 0,035 & 0,035 & 0,035 \\ \hline
    12x12 & PCA c-var & 0,056 & 0,129 & 0,064 & 0,16  & 0,219 & 0,058 & 0,083 & 0,424 & 0,038 & 0,591 & 0,038 \\
          & PCA c-mean & 0,028 & 0,111 & 0,035 & 0,149 & 0,179 & 0,035 & 0,045 & 0,042 & 0,02  & 0,02  & 0,02 \\
          & PCA domain & 0,035 & 0,118 & 0,045 & 0,151 & 0,189 & 0,046 & 0,043 & 0,041 & 0,019 & 0,024 & 0,019 \\
          & PCA pixels & 0,03  & 0,113 & 0,039 & 0,144 & 0,193 & 0,028 & 0,046 & 0,042 & 0,022 & 0,024 & 0,022 \\
          & pixels & 0,043 & 0,899 & 0,744 & 0,142 & 0,174 & 0,042 & 0,051 & 0,048 & 0,034 & 0,029 & 0,029 \\ \hline
    13x13 & PCA c-var & 0,034 & 0,112 & 0,053 & 0,148 & 0,2   & 0,041 & 0,072 & 0,416 & 0,033 & 0,62  & 0,033 \\
          & PCA c-mean & 0,023 & 0,113 & 0,035 & 0,145 & 0,188 & 0,028 & 0,047 & 0,04  & 0,023 & 0,023 & 0,023 \\
          & PCA domain & 0,032 & 0,103 & 0,031 & 0,13  & 0,18  & 0,039 & 0,048 & 0,044 & 0,031 & 0,025 & 0,025 \\
          & PCA pixels & 0,034 & 0,113 & 0,048 & 0,148 & 0,179 & 0,039 & 0,046 & 0,042 & 0,029 & 0,028 & 0,028 \\
          & pixels & 0,037 & 0,9   & 0,733 & 0,114 & 0,154 & 0,037 & 0,053 & 0,043 & 0,025 & 0,026 & 0,025 \\ \hline
          & min   & 0,023 & 0,089 & 0,031 & 0,11  & 0,146 & 0,028 & 0,035 & 0,025 & 0,019 & \textbf{0,017} & 0,017 \\
    \hline
    \end{tabular}%
		  \caption{Error rates on PCA mapped and raw pixels for bilinear interpolation between pixels}   \label{table: errorrates of PCA mappings bilinear}%
\end{table}%



\bibliographystyle{abbrv}
\nocite{*}
\bibliography{pr-ocr-assignment-report}

\end{document}
